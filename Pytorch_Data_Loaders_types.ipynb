{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Data Loaders types",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKMJgp3L1nkL",
        "colab_type": "text"
      },
      "source": [
        "##MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znj5sCrX1lB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mnist_data():\n",
        "  #transforms.Compose makes multiple transformations at once.\n",
        "  #transforms.Normalize((mean1,mean2. . . mean n), (std1, std2. . . std n)) normalized n dimensional data with respective means and standard deviations\n",
        "  compose=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "  out_dir='./dataset' #Directory where mnist needs to be downladed\n",
        "  #download the mnist dataset in output directory 'out_dir' and applies transformations 'compose'\n",
        "  # here the dataset is returned as a tensor\n",
        "  return datasets.MNIST(root=out_dir,train=True,transform=compose, download=True)\n",
        "\n",
        "data=mnist_data()\n",
        "\n",
        "data_loader=torch.utils.data.DataLoader(data, batch_size=100,shuffle=True)\n",
        "num_batches=len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67jKD90s1t19",
        "colab_type": "text"
      },
      "source": [
        "##CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XztmV3ye1wL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "train_size=int(train_split*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "trainset, valset=torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print(\"Size of train set\",len(trainloader))\n",
        "print(\"Size of val set\",len(valloader))\n",
        "print(\"Size of test set\",len(testloader))\n",
        "\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "print(\"Size of images\",images.size())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm03I1er1yeu",
        "colab_type": "text"
      },
      "source": [
        "##Custom Data loader template "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY9R54zv15wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLCxgfxB16P8",
        "colab_type": "text"
      },
      "source": [
        "##Pair wise image mapping Data loader\n",
        "Images with same label in two folder train A and train B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6g8HEVo2DuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVJ9TJqK2EHy",
        "colab_type": "text"
      },
      "source": [
        "##Pair wise image mapping Data loader with one OCR image and a text generated image\n",
        "Image with label in folder train. Pair image generated using label"
      ]
    }
  ]
}